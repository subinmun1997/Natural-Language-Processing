{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 내용\n",
    "\n",
    "* 언어 모델 : 단어 시퀀스에 확률을 할당하는 것\n",
    "* N-gram 언어 모델 : 문장에서 n개의 연속딘 단어에 대한 모델\n",
    "* Perplexity : 언어 모델의 성능을 평가하기 위한 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 언어 모델(Language model)\n",
    "\n",
    "* 문장에서의 단어 시퀀스에 확률을 할당하는 것. 이전 단어들이 주어졌을 때 다음 단어를 예측하는데 사용할 수 있음\n",
    "* 음성 인식이나 번역, 오타 교정 등에서 보다 가능성이 높은 결과를 찾기 위한 수단으로 사용될 수 있음\n",
    "\n",
    "* 단어 시퀀스의 확률 할당 사례\n",
    "  - P(나는 버스를 탔다) > P(나느 버스를 태운다)\n",
    "  - 선생님이 교실로 부리나케 P(달려갔다) > P(잘려갔다)\n",
    "  - P(나는 메롱을 먹는다) < P(나는 메론을 먹는다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 시퀀스를 확률로 나타내기\n",
    "\n",
    "* 단어 시퀀스의 확률 : 하나의 단어를 w, 단어 시퀀스를 W라고 하면, n개의 단어가 등장하는 시퀀스 W의 확률은 다음과 같음\n",
    "                       P(W) = P(w1,w2,w3,...,w(n))\n",
    "* 다음 단어 등장 확률은 조건부 확률(conditional probability)로 표시\n",
    "  P(w(n)| w1,w2,...w(n-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계적 언어 모델(Statistical language model)\n",
    "\n",
    "* 통계적 언어 모델(SLM)에서는 조건부 확률 관계식을 이용함\n",
    "  P(B|A) = P(A,B) / P(A) \n",
    "  P(A,B) = P(A)P(B|A)\n",
    "  \n",
    "* 조건부 확률의 연쇄 법칙(chain rule)\n",
    "  P(x1,x2,...,x(n)) = P(x1)P(x2|x1)...P(x(n)|x1x2...x(n-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장에 대한 확률\n",
    "\n",
    "* 문장의 확률을 구하기 위해 각 단어에 대한 예측 확률들을 곱합\n",
    "\n",
    "* 예) 문장 'An adorable little boy is spreading smiles'의 확률을 식으로 표현하는 방법\n",
    "      P(An adorable little boy is spreading smiles) = P(An) * P(adorable | An) * P(little | An adorable) * P(boy | An adorable little) * P(is | An adorable little boy) * P(spreading | An adorable little boy is) * P(smiles | An adorable little boy is spreading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카운트 기반의 접근과 한계\n",
    "\n",
    "* 문장의 확률을 알려면 단어에 대한 예측 확률을 알아야 함\n",
    "* SLM에서는 코퍼스(corpus) 데이터를 학습하여 근사 확률을 계산함\n",
    "* 어느 정도 정확한 확률을 구하려면 방대한 양의 데이터가 필요함\n",
    "* 희소 문제(Sparsity problem) :  기계가 훈련한 코퍼스에 해당 시퀀스가 존재하지 않으면 이 확률은 0이 됨. \n",
    "                                 이 문제를 해결하기 위해 smoothing이나 backoff과 같은 일반화 기법을 적용함\n",
    "* 이와 같은 한계로 인해 언어 모델 기법은 SLM에서 인공 신경망 언어 모델로 넘어가게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram 언어 모델\n",
    "\n",
    "* SLM 방식의 일종인데, 앞의 n-1개까지만 고려함\n",
    "* 이 방식을 이용하면 코퍼스에서 각 시퀀스를 카운트할 확률이 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram 언어 모델의 한계\n",
    "\n",
    "* 희소 문제 : 작은 시퀀스에 대한 등장 확률이 높아지지만 여전히 등장하지 않을 가능성이 있음\n",
    "* n을 선택하는 것은 trade-off 문제 : n을 크게 선택하면 희소 문제가 심각해짐. (n은 최대 5개를 넘게 잡아서는 안된다고 권장함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어에서의 언어 모델\n",
    "\n",
    "* 한국어 자연어 처리는 다음의 이유들로 영어보다 훨씬 어려움\n",
    "\n",
    "1. 한국어는 어순이 중요하지 않다 : 확률 기반 모델이 다음 단어를 예측하기 어려움\n",
    "2. 한국어는 교착어이다 : 조사가 붙으므로 이를 분리하는 것이 중요함\n",
    "3. 한국어는 띄어쓰기가 제대로 지켜지지 않는다 :  토큰이 제대로 분리되지 않으면 언어 모델이 제대로 동작하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 발생 확률의 근사적 처리\n",
    "\n",
    "* 말뭉치에 없는 문장에 대해서 작은 확률값을 배정하기 위해 Back-off와 Smoothing 방식을 사용\n",
    "* Smoothing 기법 : 등장 빈도 표에 모두 k를 더함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "\n",
    "* 언어 모델의 성능을 비교하기 위해 테스트 데이터를 이용하여 평가하는 방식으로 perplexity(PPL)가 있음\n",
    "* 테스트 데이터에서 확률의 역수로 정의되는데, PPL이 낮을수록 언어 모델의 성능이 좋은 것임\n",
    "* PPL은 현재 위치에서 선택할 수 있는 가지의 개수를 의미하므로, 이 숫자가 크면 불확실성이 높다고 할 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
