{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 내용\n",
    "\n",
    "* Topic model : 문서의 주제를 찾아내서 문서들을 비교/분류 하는 것\n",
    "* 잠재 의미 분석(Latent Semantic Analysis) : SVD 방식을 이용하여 주제를 찾아냄\n",
    "* 잠재 디리클레 할당(Latent Dirichlet Allocation) : 확률 모형을 통해 주제를 찾아냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "\n",
    "* 토픽 모델링은 사용된 단어들을 분석하여 문서에 포함되어 있는 주제를 찾아내고자 함\n",
    "* 규칙 기반 방식을 사용하지 않고 문서 분석 알고리즘을 사용\n",
    "* 텍스트 분류와 유사하지만 토픽 모델링에서는 문서에 내재된 주제를 숫자로 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잠재 의미 분석(Latent Semantic Analysis)\n",
    "\n",
    "* 여러 문서로부터 추출된 DTM(Document-term matrix)에 SVD(Singular Value Decomposition)기법을 적용하여 주제를 찾아내는 방식\n",
    "* DTM의 관심 영역을 축소하여 문서들에 내재된 주제를 찾아내는 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특이값 분해(Singular Value Decomposition)\n",
    "\n",
    "* A가 m * n 행렬일 때 다음과 같이 3개의 행렬의 곱으로 분해하는 것\n",
    "  A = U∑V*\n",
    "  \n",
    "* 각 행렬은 다음 성질을 가짐\n",
    "  U : m * m 직교행렬(UU* = I)\n",
    "  ∑ : m * n 직사각 대각행렬\n",
    "  V : n * n 직교행렬(VV* = I)\n",
    "* 직교행렬(orthogonal matrix) : 한 행의 크기(norm)는 1이고, 서로 다른 행들간의 내적은 0임.\n",
    "* SVD는 numpy와 같은 패키지를 이용하여 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD 조절에 의한 차원 축소(dimensionality reduction)\n",
    "\n",
    "* ∑행렬의 원소 숫자(topic 숫자)를 줄여서 DTM A를 변형시킴\n",
    "* 이와 같이 적은 수의 topic에 집중함으로써 A의 차원을 줄이게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 특이값의 중요도\n",
    "\n",
    "* ∑행렬의 원소 값들은 해당 topic의 중요성을 반영함\n",
    "* 상대적으로 낮은 값들을 0으로 만들면 덜 중요한 topic을 고려하지 않는 결과가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA 처리 절차\n",
    "\n",
    "1. 총 n개의 단어를 포함하고 있는 m개의 문서에서 m * n크기의 DTM A를 생성. 필요한 경우 단어에서 불용어를 제거\n",
    "2. A에 대해 SVD를 적용하여 A = U∑V*를 만족시키는 세 행렬을 구함\n",
    "3. ∑의 원소 중 K개의 큰 값을 선정(주요 토픽을 선정하는 과정)\n",
    "4. U와 V에서 K개의 행과 열 만을 남긴 U(t)와 V(t)를 구함. U(t)와 V(t)에서는 각 문서에서 K개의 주제가 차지하는 비중, 그리고 각 주제에서 단    어들이 차지하는 비중을 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA 응용 분야\n",
    "\n",
    "* LSA는 차원 축소(dimensionality reduction)에 사용됨. 단어가 10만개, 문서가 10,000개 있는 경우 DTM 규모는 100,000 * 10,000 크기이지만\n",
    "  수백개 정도의 topic으로 축소할 수 있음\n",
    "* LSA는 검색 엔진에 사용됨. 이 경우 Latent Semantic Indexing(LSI)이라는 명칭도 사용\n",
    "* 문서 군집화(clustering)에 사용될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잠재 디리클레 할당(LDA)\n",
    "\n",
    "* 문서(신문 기사, 논문 등)의 주제와 주제 단어들을 찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA 분석 방법\n",
    "\n",
    "* 입력 : 다수의 문서(기사, 논문, 웹 문서 등등)에서 추출된 DTM\n",
    "* 전제 조건 : Topic의 숫자\n",
    "* 분석 방법 : Gibbs sampling과 같은 통계적 분석 기법으로 문서별 topic 분포와 각 topic의 주요 단어들을 찾아 냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA 수행 절차\n",
    "\n",
    "* 확률적 모델링(probabilistic modeling) 방식을 사용\n",
    "* 수행 절차는 다소 복잡함\n",
    "* 데이터 분석 모듈에 기능이 제공되고 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
